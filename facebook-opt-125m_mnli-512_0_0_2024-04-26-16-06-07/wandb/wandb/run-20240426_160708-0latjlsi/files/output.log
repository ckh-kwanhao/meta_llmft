Trainable parameters: ['model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'model.decoder.layers.0.self_attn.query_adapter.scale', 'model.decoder.layers.0.self_attn.query_adapter.down.weight', 'model.decoder.layers.0.self_attn.query_adapter.down.bias', 'model.decoder.layers.0.self_attn.query_adapter.up.weight', 'model.decoder.layers.0.self_attn.query_adapter.up.bias', 'model.decoder.layers.0.self_attn.value_adapter.scale', 'model.decoder.layers.0.self_attn.value_adapter.down.weight', 'model.decoder.layers.0.self_attn.value_adapter.down.bias', 'model.decoder.layers.0.self_attn.value_adapter.up.weight', 'model.decoder.layers.0.self_attn.value_adapter.up.bias', 'model.decoder.layers.1.self_attn.query_adapter.scale', 'model.decoder.layers.1.self_attn.query_adapter.down.weight', 'model.decoder.layers.1.self_attn.query_adapter.down.bias', 'model.decoder.layers.1.self_attn.query_adapter.up.weight', 'model.decoder.layers.1.self_attn.query_adapter.up.bias', 'model.decoder.layers.1.self_attn.value_adapter.scale', 'model.decoder.layers.1.self_attn.value_adapter.down.weight', 'model.decoder.layers.1.self_attn.value_adapter.down.bias', 'model.decoder.layers.1.self_attn.value_adapter.up.weight', 'model.decoder.layers.1.self_attn.value_adapter.up.bias', 'model.decoder.layers.2.self_attn.query_adapter.scale', 'model.decoder.layers.2.self_attn.query_adapter.down.weight', 'model.decoder.layers.2.self_attn.query_adapter.down.bias', 'model.decoder.layers.2.self_attn.query_adapter.up.weight', 'model.decoder.layers.2.self_attn.query_adapter.up.bias', 'model.decoder.layers.2.self_attn.value_adapter.scale', 'model.decoder.layers.2.self_attn.value_adapter.down.weight', 'model.decoder.layers.2.self_attn.value_adapter.down.bias', 'model.decoder.layers.2.self_attn.value_adapter.up.weight', 'model.decoder.layers.2.self_attn.value_adapter.up.bias', 'model.decoder.layers.3.self_attn.query_adapter.scale', 'model.decoder.layers.3.self_attn.query_adapter.down.weight', 'model.decoder.layers.3.self_attn.query_adapter.down.bias', 'model.decoder.layers.3.self_attn.query_adapter.up.weight', 'model.decoder.layers.3.self_attn.query_adapter.up.bias', 'model.decoder.layers.3.self_attn.value_adapter.scale', 'model.decoder.layers.3.self_attn.value_adapter.down.weight', 'model.decoder.layers.3.self_attn.value_adapter.down.bias', 'model.decoder.layers.3.self_attn.value_adapter.up.weight', 'model.decoder.layers.3.self_attn.value_adapter.up.bias', 'model.decoder.layers.4.self_attn.query_adapter.scale', 'model.decoder.layers.4.self_attn.query_adapter.down.weight', 'model.decoder.layers.4.self_attn.query_adapter.down.bias', 'model.decoder.layers.4.self_attn.query_adapter.up.weight', 'model.decoder.layers.4.self_attn.query_adapter.up.bias', 'model.decoder.layers.4.self_attn.value_adapter.scale', 'model.decoder.layers.4.self_attn.value_adapter.down.weight', 'model.decoder.layers.4.self_attn.value_adapter.down.bias', 'model.decoder.layers.4.self_attn.value_adapter.up.weight', 'model.decoder.layers.4.self_attn.value_adapter.up.bias', 'model.decoder.layers.5.self_attn.query_adapter.scale', 'model.decoder.layers.5.self_attn.query_adapter.down.weight', 'model.decoder.layers.5.self_attn.query_adapter.down.bias', 'model.decoder.layers.5.self_attn.query_adapter.up.weight', 'model.decoder.layers.5.self_attn.query_adapter.up.bias', 'model.decoder.layers.5.self_attn.value_adapter.scale', 'model.decoder.layers.5.self_attn.value_adapter.down.weight', 'model.decoder.layers.5.self_attn.value_adapter.down.bias', 'model.decoder.layers.5.self_attn.value_adapter.up.weight', 'model.decoder.layers.5.self_attn.value_adapter.up.bias', 'model.decoder.layers.6.self_attn.query_adapter.scale', 'model.decoder.layers.6.self_attn.query_adapter.down.weight', 'model.decoder.layers.6.self_attn.query_adapter.down.bias', 'model.decoder.layers.6.self_attn.query_adapter.up.weight', 'model.decoder.layers.6.self_attn.query_adapter.up.bias', 'model.decoder.layers.6.self_attn.value_adapter.scale', 'model.decoder.layers.6.self_attn.value_adapter.down.weight', 'model.decoder.layers.6.self_attn.value_adapter.down.bias', 'model.decoder.layers.6.self_attn.value_adapter.up.weight', 'model.decoder.layers.6.self_attn.value_adapter.up.bias', 'model.decoder.layers.7.self_attn.query_adapter.scale', 'model.decoder.layers.7.self_attn.query_adapter.down.weight', 'model.decoder.layers.7.self_attn.query_adapter.down.bias', 'model.decoder.layers.7.self_attn.query_adapter.up.weight', 'model.decoder.layers.7.self_attn.query_adapter.up.bias', 'model.decoder.layers.7.self_attn.value_adapter.scale', 'model.decoder.layers.7.self_attn.value_adapter.down.weight', 'model.decoder.layers.7.self_attn.value_adapter.down.bias', 'model.decoder.layers.7.self_attn.value_adapter.up.weight', 'model.decoder.layers.7.self_attn.value_adapter.up.bias', 'model.decoder.layers.8.self_attn.query_adapter.scale', 'model.decoder.layers.8.self_attn.query_adapter.down.weight', 'model.decoder.layers.8.self_attn.query_adapter.down.bias', 'model.decoder.layers.8.self_attn.query_adapter.up.weight', 'model.decoder.layers.8.self_attn.query_adapter.up.bias', 'model.decoder.layers.8.self_attn.value_adapter.scale', 'model.decoder.layers.8.self_attn.value_adapter.down.weight', 'model.decoder.layers.8.self_attn.value_adapter.down.bias', 'model.decoder.layers.8.self_attn.value_adapter.up.weight', 'model.decoder.layers.8.self_attn.value_adapter.up.bias', 'model.decoder.layers.9.self_attn.query_adapter.scale', 'model.decoder.layers.9.self_attn.query_adapter.down.weight', 'model.decoder.layers.9.self_attn.query_adapter.down.bias', 'model.decoder.layers.9.self_attn.query_adapter.up.weight', 'model.decoder.layers.9.self_attn.query_adapter.up.bias', 'model.decoder.layers.9.self_attn.value_adapter.scale', 'model.decoder.layers.9.self_attn.value_adapter.down.weight', 'model.decoder.layers.9.self_attn.value_adapter.down.bias', 'model.decoder.layers.9.self_attn.value_adapter.up.weight', 'model.decoder.layers.9.self_attn.value_adapter.up.bias', 'model.decoder.layers.10.self_attn.query_adapter.scale', 'model.decoder.layers.10.self_attn.query_adapter.down.weight', 'model.decoder.layers.10.self_attn.query_adapter.down.bias', 'model.decoder.layers.10.self_attn.query_adapter.up.weight', 'model.decoder.layers.10.self_attn.query_adapter.up.bias', 'model.decoder.layers.10.self_attn.value_adapter.scale', 'model.decoder.layers.10.self_attn.value_adapter.down.weight', 'model.decoder.layers.10.self_attn.value_adapter.down.bias', 'model.decoder.layers.10.self_attn.value_adapter.up.weight', 'model.decoder.layers.10.self_attn.value_adapter.up.bias', 'model.decoder.layers.11.self_attn.query_adapter.scale', 'model.decoder.layers.11.self_attn.query_adapter.down.weight', 'model.decoder.layers.11.self_attn.query_adapter.down.bias', 'model.decoder.layers.11.self_attn.query_adapter.up.weight', 'model.decoder.layers.11.self_attn.query_adapter.up.bias', 'model.decoder.layers.11.self_attn.value_adapter.scale', 'model.decoder.layers.11.self_attn.value_adapter.down.weight', 'model.decoder.layers.11.self_attn.value_adapter.down.bias', 'model.decoder.layers.11.self_attn.value_adapter.up.weight', 'model.decoder.layers.11.self_attn.value_adapter.up.bias']
checkpoint None
do_train:  True
do_eval:  True
do_predict:  False
resume_from_checkpoint:  None
output_dir:  /logfiles/facebook-opt-125m_mnli-512_0_0_2024-04-26-16-06-07
Using /cache/torch as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /cache/torch/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module fused_adam...
Time to load fused_adam op: 0.1715259552001953 seconds
Using /cache/torch as PyTorch extensions root...
Emitting ninja build file /cache/torch/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
Loading extension module utils...
Time to load utils op: 0.1623244285583496 seconds
Parameter Offload: Total persistent parameters: 434904 in 242 params
Using /cache/torch as PyTorch extensions root...
  1%|▊                                                                                                              | 1/128 [00:01<02:13,  1.05s/it][WARNING|trainer_pt_utils.py:849] 2024-04-26 16:07:15,612 >> tried to get lr value before scheduler/optimizer started stepping, returning lr=0
  1%|▊                                                                                                              | 1/128 [00:01<02:13,  1.05s/it]
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0025177001953125 seconds























100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128/128 [00:48<00:00,  1.11it/s]
  0%|                                                                                                                       | 0/500 [00:00<?, ?it/s]








































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:17<00:00,  6.66it/s]
{'eval_hans-lexical_overlap-entailment_loss': 0.1029052734375, 'eval_hans-lexical_overlap-entailment_accuracy': 0.9788, 'eval_hans-lexical_overlap-entailment_frac_non_target_tokens': 0.0, 'eval_hans-lexical_overlap-entailment_runtime': 80.1442, 'eval_hans-lexical_overlap-entailment_samples_per_second': 62.388, 'eval_hans-lexical_overlap-entailment_steps_per_second': 6.239, 'epoch': 1.0}





































  0%|                                                                                                                       | 0/670 [00:00<?, ?it/s]




















































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 670/670 [01:40<00:00,  6.52it/s]
{'eval_mnli_loss': 0.69677734375, 'eval_mnli_accuracy': 0.6507770472205618, 'eval_mnli_frac_non_target_tokens': 0.00014943215780035862, 'eval_mnli_runtime': 103.647, 'eval_mnli_samples_per_second': 64.565, 'eval_mnli_steps_per_second': 6.464, 'epoch': 1.0}
{'train_runtime': 309.5162, 'train_samples_per_second': 1.654, 'train_steps_per_second': 0.414, 'train_loss': 1.4302172660827637, 'epoch': 1.0}
Saving model
Saving tokenizer
Traceback (most recent call last):
  File "/llmft/ft_20240426.py", line 831, in <module>
  File "/llmft/ft_20240426.py", line 748, in main
  File "/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py", line 2629, in from_pretrained
    model = cls(config, *model_args, **model_kwargs)
  File "/opt/conda/lib/python3.8/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 355, in wrapper
    f(module, *args, **kwargs)
  File "/llmft/models/opt_wrapper.py", line 636, in __init__
    super().__init__(config)
  File "/opt/conda/lib/python3.8/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 355, in wrapper
    f(module, *args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/transformers/models/opt/modeling_opt.py", line 817, in __init__
    self.model = OPTModel(config)
  File "/opt/conda/lib/python3.8/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 355, in wrapper
    f(module, *args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/transformers/models/opt/modeling_opt.py", line 749, in __init__
    self.decoder = OPTDecoder(config)
  File "/opt/conda/lib/python3.8/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 355, in wrapper
    f(module, *args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/transformers/models/opt/modeling_opt.py", line 520, in __init__
    self.layers = nn.ModuleList([OPTDecoderLayer(config) for _ in range(config.num_hidden_layers)])
  File "/opt/conda/lib/python3.8/site-packages/transformers/models/opt/modeling_opt.py", line 520, in <listcomp>
    self.layers = nn.ModuleList([OPTDecoderLayer(config) for _ in range(config.num_hidden_layers)])
  File "/opt/conda/lib/python3.8/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 355, in wrapper
    f(module, *args, **kwargs)
  File "/llmft/models/opt_wrapper.py", line 321, in __init__
    print("Adapter type: ", config.adapter_type)
  File "/opt/conda/lib/python3.8/site-packages/transformers/configuration_utils.py", line 260, in __getattribute__
    return super().__getattribute__(key)
AttributeError: 'OPTConfig' object has no attribute 'adapter_type'
Reloading model
Using adapters